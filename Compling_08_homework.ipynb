{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00fad453",
      "metadata": {
        "id": "00fad453"
      },
      "source": [
        "# Домашнее задание № 4. Языковые модели"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d056af4",
      "metadata": {
        "id": "5d056af4"
      },
      "source": [
        "## Задание 1 (8 баллов)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1f532a8",
      "metadata": {
        "id": "d1f532a8"
      },
      "source": [
        "В семинаре для генерации мы использовали предположение маркова и считали, что слово зависит только от 1 предыдущего слова. Но ничто нам не мешает попробовать увеличить размер окна и учитывать два или даже три прошлых слова. Для них мы еще сможем собрать достаточно статистик и, логично предположить, что качество сгенерированного текста должно вырасти."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de743d1d",
      "metadata": {
        "id": "de743d1d"
      },
      "source": [
        "Попробуйте сделать языковую модель, которая будет учитывать два предыдущих слова при генерации текста.\n",
        "Сгенерируйте несколько текстов (3-5) и расчитайте перплексию получившейся модели.\n",
        "Можно использовать данные из семинара или любые другие (можно брать только часть текста, если считается слишком долго). Перплексию рассчитывайте на 10-50 отложенных предложениях (они не должны использоваться при сборе статистик).\n",
        "\n",
        "\n",
        "Подсказки:  \n",
        "    - нужно будет добавить еще один тэг \\<start>  \n",
        "    - можете использовать тот же подход с матрицей вероятностей, но по строкам хронить биграмы, а по колонкам униграммы\n",
        "    - тексты должны быть очень похожи на нормальные (если у вас получается рандомная каша, вы что-то делаете не так)\n",
        "    - у вас будут словари с индексами биграммов и униграммов, не перепутайте их при переводе индекса в слово - словарь биграммов будет больше словаря униграммов и все индексы из униграммного словаря будут формально подходить для словаря биграммов (не будет ошибки при id2bigram[unigram_id]), но маппинг при этом будет совершенно неправильным"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install razdel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFy6kv9f7e7i",
        "outputId": "eabe5506-72c9-418a-82f9-c46675100e6d"
      },
      "id": "lFy6kv9f7e7i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting razdel\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: razdel\n",
            "Successfully installed razdel-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6afcef88",
      "metadata": {
        "id": "6afcef88"
      },
      "outputs": [],
      "source": [
        "from string import punctuation\n",
        "from razdel import sentenize\n",
        "from razdel import tokenize as razdel_tokenize\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmZ8N8mG6xsf",
        "outputId": "06dc60fc-db41-4170-a86b-0745bb42f56d"
      },
      "id": "pmZ8N8mG6xsf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news = open('/content/drive/MyDrive/Colab Notebooks/lenta.txt').read()"
      ],
      "metadata": {
        "id": "mFiKZTEE68DV"
      },
      "id": "mFiKZTEE68DV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_sent = [sent.text for sent in list(sentenize(news))]\n",
        "random.shuffle(news_sent)"
      ],
      "metadata": {
        "id": "Zgi6I0xR87KN"
      },
      "id": "Zgi6I0xR87KN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_sent_main = news_sent[50:]\n",
        "news_sent_test = news_sent[:50]"
      ],
      "metadata": {
        "id": "6apxMesR9E6l"
      },
      "id": "6apxMesR9E6l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(text):\n",
        "    normalized_text = [word.text.strip(punctuation) for word \\\n",
        "                                                            in razdel_tokenize(text)]\n",
        "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
        "    return normalized_text"
      ],
      "metadata": {
        "id": "OPRFkVzq7MDt"
      },
      "id": "OPRFkVzq7MDt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_news = normalize(' '.join(news_sent_main))"
      ],
      "metadata": {
        "id": "u8c6u6aP725U"
      },
      "id": "u8c6u6aP725U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_news = Counter(norm_news)\n",
        "probas_news = Counter({word:c/len(norm_news) for word, c in vocab_news.items()})"
      ],
      "metadata": {
        "id": "XaqBG8wH-sbs"
      },
      "id": "XaqBG8wH-sbs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ngrammer(tokens, n=2):\n",
        "    ngrams = []\n",
        "    for i in range(0, len(tokens) - n + 1):\n",
        "        ngrams.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams"
      ],
      "metadata": {
        "id": "kpokTRvBLNMm"
      },
      "id": "kpokTRvBLNMm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_news = [['<start1>', '<start2>'] + normalize(text) + ['<end>'] for text in news_sent_main]"
      ],
      "metadata": {
        "id": "s1HfwwvaL4d5"
      },
      "id": "s1HfwwvaL4d5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unigrams_news = Counter()\n",
        "bigrams_news = Counter()\n",
        "trigrams_news = Counter()\n",
        "\n",
        "for sentence in sentences_news:\n",
        "    unigrams_news.update(sentence)\n",
        "    bigrams_news.update(ngrammer(sentence))\n",
        "    trigrams_news.update(ngrammer(sentence, 3))"
      ],
      "metadata": {
        "id": "897N0EwZMaha"
      },
      "id": "897N0EwZMaha",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import lil_matrix, csr_matrix, csc_matrix\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "vJYlZg_0OLAI"
      },
      "id": "vJYlZg_0OLAI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_news = lil_matrix((len(bigrams_news),\n",
        "                        len(unigrams_news)))\n",
        "\n",
        "id2word_news = list(unigrams_news)\n",
        "word2id_news = {word:i for i, word in enumerate(id2word_news)}\n",
        "\n",
        "id2bigr_news =list(bigrams_news)\n",
        "bigr2id_news = {bigr:i for i, bigr in enumerate(id2bigr_news)}\n",
        "\n",
        "\n",
        "for ngram in trigrams_news:\n",
        "    bigr = ' '.join(ngram.split()[:2])\n",
        "    word = ngram.split()[2]\n",
        "    matrix_news[bigr2id_news[bigr], word2id_news[word]] =  (trigrams_news[ngram]/\n",
        "                                                                     bigrams_news[bigr])\n",
        "\n",
        "matrix_news = csc_matrix(matrix_news)"
      ],
      "metadata": {
        "id": "vIb6lJ_eOMSp"
      },
      "id": "vIb6lJ_eOMSp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_temperature(probas, temperature):\n",
        "    # логарифмирование и деление на температуру\n",
        "    log_probas = np.log(np.maximum(probas, 1e-10))\n",
        "    adjusted_log_probas = log_probas / temperature\n",
        "    # чтобы получить честные вероятности, нужно применить софтмакс\n",
        "    exp_probas = np.exp(adjusted_log_probas)\n",
        "    adjusted_probabilities = exp_probas / np.sum(exp_probas)\n",
        "    return adjusted_probabilities"
      ],
      "metadata": {
        "id": "byxqvO8ql4sI"
      },
      "id": "byxqvO8ql4sI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#версия 1 (без Beam)\n",
        "def generate(matrix, id2word, bigr2id, n=100, start='<start1> <start2>', temperature=1.2):\n",
        "    text = []\n",
        "    current_idx = bigr2id[start]\n",
        "    current_bigr_split = start.split()\n",
        "\n",
        "    for i in range(n):\n",
        "        probas = matrix[current_idx].toarray()[0]\n",
        "\n",
        "        if probas.sum() == 0:\n",
        "            chosen = np.random.randint(0, matrix.shape[1])\n",
        "        else:\n",
        "            chosen = np.random.choice(\n",
        "                matrix.shape[1],\n",
        "                p=apply_temperature(probas, temperature=temperature)\n",
        "            )\n",
        "\n",
        "        chosen_word = id2word[chosen]\n",
        "        text.append(chosen_word)\n",
        "\n",
        "        if chosen_word == '<end>':\n",
        "            current_idx = bigr2id[start]\n",
        "            current_bigr_split = start.split()\n",
        "        else:\n",
        "            current_bigr_split = [current_bigr_split[1], chosen_word]\n",
        "            new_bigr = ' '.join(current_bigr_split)\n",
        "\n",
        "            if new_bigr in bigr2id:\n",
        "                current_idx = bigr2id[new_bigr]\n",
        "            else:\n",
        "                second_token = current_bigr_split[0]\n",
        "                candidates = [bigr for bigr in bigr2id.keys() if bigr.split()[1] == second_token]\n",
        "                if candidates:\n",
        "                    current_idx = bigr2id[random.choice(candidates)]\n",
        "                else:\n",
        "                    try:\n",
        "                        current_idx = bigr2id[start]\n",
        "                    except:\n",
        "                        raise KeyError('Генерация с таким стартом невозможна')\n",
        "\n",
        "    return ' '.join(text)\n"
      ],
      "metadata": {
        "id": "815wsgs3hS9Q"
      },
      "id": "815wsgs3hS9Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(3):\n",
        "    print(generate(matrix_news, id2word_news, bigr2id_news).replace(' <end>', '.'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHp9GzbwWIXf",
        "outputId": "6945735d-f4ce-46a1-b492-dbefc45f8dee"
      },
      "id": "oHp9GzbwWIXf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "запертые журналисты подняли тревогу и озабоченность заявил исполняющий обязанности министра обороны сообщает reuters в последний путь погибших при взрыве произошедшем в связи с осложнением обстановки в чечне будет амнистирована еще одна небольшая снежная лавина. коллина сообщил представителям уефа о том что китайское правительство разрабатывает новые правила разработаны с целью обнаружения взрывоопасных предметов оставленных боевиками. именно кандидатуру артемьева яблоко собиралось поддерживать на несостоявшихся губернаторских выборах. несмотря на множество встреч и от всей конструкции и пролетел 20 метров. на место происшествия прибыли сорудники скорой помощи им склифосовского 1-ая градская 36-ая и 64-ая горбольница работают только на сумму 325\n",
            "наконец в мосгоризбирком подал заявление об отставке. как сообщили интерфаксу в аппарате полномочного представителя президента россии самарского губернатора председателя политсовета петербургского движения яблока. леонид кучма решивший обзавестись собственным сервером в интернете. по мнению аушева назначение кадырова результат действий военного лобби того самого элиакима рубенштейна который в случае положительного решения послужило то что зараза переселяется в компьютер пользователя при посещении сайтов идентифицируют программное обеспечение предназначенное для лечения диабета антибиотики и вакцины. владимир татаренков воглавлял преступную группировку в городе бийске алтайского края почти не отличаются от шансов неожиданно скончаться на земле катастрофа случилась в 21 10 по местному\n",
            "полностью выгорело 17 тысяч человек. рубин заявил что сотрудники министерства определили что граната учебная. кроме того лидер спс считает бесспорно незаконной. во вторник кабельная компании ntl сообщила что в результате которой участники получили около 50 метров во время планового обхода территории заповедника. питерцы победили со счетом 75 55 31 33 третий решающий матч серии до трех с лишним тысяч рублей. все участковые комиссии в которую опускают бюллетени. виктор черепков он набрал при голосовании по кандидатуре надолжность спикера нижней палаты парламента боснии и герцеговине. церетели сообщил что всего существует около 4,1 миллиона таких счетов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "запертые журналисты подняли тревогу и озабоченность заявил исполняющий обязанности министра обороны сообщает reuters в последний путь погибших при взрыве произошедшем в связи с осложнением обстановки в чечне будет амнистирована еще одна небольшая снежная лавина. коллина сообщил представителям уефа о том что китайское правительство разрабатывает новые правила разработаны с целью обнаружения взрывоопасных предметов оставленных боевиками. именно кандидатуру артемьева яблоко собиралось поддерживать на несостоявшихся губернаторских выборах. несмотря на множество встреч и от всей конструкции и пролетел 20 метров. на место происшествия прибыли сорудники скорой помощи им склифосовского 1-ая градская 36-ая и 64-ая горбольница работают только на сумму 325\n",
        "\n",
        "наконец в мосгоризбирком подал заявление об отставке. как сообщили интерфаксу в аппарате полномочного представителя президента россии самарского губернатора председателя политсовета петербургского движения яблока. леонид кучма решивший обзавестись собственным сервером в интернете. по мнению аушева назначение кадырова результат действий военного лобби того самого элиакима рубенштейна который в случае положительного решения послужило то что зараза переселяется в компьютер пользователя при посещении сайтов идентифицируют программное обеспечение предназначенное для лечения диабета антибиотики и вакцины. владимир татаренков воглавлял преступную группировку в городе бийске алтайского края почти не отличаются от шансов неожиданно скончаться на земле катастрофа случилась в 21 10 по местному\n",
        "\n",
        "полностью выгорело 17 тысяч человек. рубин заявил что сотрудники министерства определили что граната учебная. кроме того лидер спс считает бесспорно незаконной. во вторник кабельная компании ntl сообщила что в результате которой участники получили около 50 метров во время планового обхода территории заповедника. питерцы победили со счетом 75 55 31 33 третий решающий матч серии до трех с лишним тысяч рублей. все участковые комиссии в которую опускают бюллетени. виктор черепков он набрал при голосовании по кандидатуре надолжность спикера нижней палаты парламента боснии и герцеговине. церетели сообщил что всего существует около 4,1 миллиона таких счетов\n"
      ],
      "metadata": {
        "id": "yxSDggMy0Ecn"
      },
      "id": "yxSDggMy0Ecn"
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(logp, N):\n",
        "    return np.exp((-1/N) * logp)"
      ],
      "metadata": {
        "id": "0CyiLIsGxW8G"
      },
      "id": "0CyiLIsGxW8G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_joint_proba(text, word_probas):\n",
        "    prob = 0\n",
        "    tokens = normalize(text)\n",
        "    for word in tokens:\n",
        "        if word in word_probas:\n",
        "            prob += (np.log(word_probas[word]))\n",
        "        else:\n",
        "            prob += np.log(2e-4)\n",
        "\n",
        "    return prob, len(tokens)"
      ],
      "metadata": {
        "id": "S-z68Bx18EfS"
      },
      "id": "S-z68Bx18EfS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_join_proba_markov_assumption(text, word_counts, bigram_counts):\n",
        "    prob = 0\n",
        "    tokens = normalize(text)\n",
        "    for ngram in ngrammer(['<start>'] + tokens + ['<end>']):\n",
        "        word1, word2 = ngram.split()\n",
        "        if word1 in word_counts and ngram in bigram_counts:\n",
        "            prob += np.log(bigram_counts[ngram]/word_counts[word1])\n",
        "        else:\n",
        "            prob += np.log(2e-5)\n",
        "\n",
        "    return prob, len(tokens)"
      ],
      "metadata": {
        "id": "XEy_o4M18EsT"
      },
      "id": "XEy_o4M18EsT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_join_proba_trigram(text, word_counts, bigram_counts, trigram_counts):\n",
        "    prob = 0\n",
        "    tokens = normalize(text)\n",
        "    for ngram in ngrammer(['<start1>', '<start2>'] + tokens + ['<end>'], 3):\n",
        "        bigr = ' '.join(ngram.split()[:2])\n",
        "        word = ngram.split()[2]\n",
        "        if bigr in bigram_counts and ngram in trigram_counts:\n",
        "            prob += np.log(trigram_counts[ngram]/bigram_counts[bigr])\n",
        "        else:\n",
        "            prob += np.log(1e-3)\n",
        "\n",
        "    return prob, len(tokens)"
      ],
      "metadata": {
        "id": "lIeJ1pLKxYkH"
      },
      "id": "lIeJ1pLKxYkH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps_1 = []\n",
        "\n",
        "for sent in news_sent_test:\n",
        "\n",
        "  prob_1, N_1 = compute_joint_proba(sent, probas_news)\n",
        "  if not N_1:\n",
        "        continue\n",
        "\n",
        "  ps_1.append(perplexity(prob_1, N_1))"
      ],
      "metadata": {
        "id": "RomKgCzXxYoJ"
      },
      "id": "RomKgCzXxYoJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps_2 = []\n",
        "\n",
        "for sent in news_sent_test:\n",
        "    prob_2, N_2 = compute_join_proba_markov_assumption(sent, unigrams_news, bigrams_news)\n",
        "\n",
        "    if not N_2:\n",
        "        continue\n",
        "\n",
        "    ps_2.append(perplexity(prob_2, N_2))"
      ],
      "metadata": {
        "id": "5B30d1lU-hYd"
      },
      "id": "5B30d1lU-hYd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps_3 = []\n",
        "\n",
        "for sent in news_sent_test:\n",
        "\n",
        "      prob_3, N_3 = compute_join_proba_trigram(sent, unigrams_news, bigrams_news, trigrams_news)\n",
        "      if not N_3:\n",
        "        continue\n",
        "\n",
        "      ps_3.append(perplexity(prob_3, N_3))"
      ],
      "metadata": {
        "id": "pGWsHJfaxYuh"
      },
      "id": "pGWsHJfaxYuh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(ps_1))\n",
        "print(np.mean(ps_2))\n",
        "print(np.mean(ps_3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dQmN3rw_b3_",
        "outputId": "065f476e-a359-4525-baef-5151c3e716af"
      },
      "id": "_dQmN3rw_b3_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9276.10350000907\n",
            "3050.868403764363\n",
            "630.3099085184163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e0a8dd5",
      "metadata": {
        "id": "8e0a8dd5"
      },
      "source": [
        "## Задание № 2* (2 балла)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f733858c",
      "metadata": {
        "id": "f733858c"
      },
      "source": [
        "Измените функцию generate_with_beam_search так, чтобы она работала с моделью, которая учитывает два предыдущих слова.\n",
        "Сравните получаемый результат с первым заданием.\n",
        "Также попробуйте начинать генерацию не с нуля (подавая \\<start> \\<start>), а с какого-то промпта. Но помните, что учитываться будут только два последних слова, так что не делайте длинные промпты."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Beam:\n",
        "    def __init__(self, sequence: list, score: float):\n",
        "        self.sequence: list = sequence\n",
        "        self.score: float = score"
      ],
      "metadata": {
        "id": "V7501LlYcsRP"
      },
      "id": "V7501LlYcsRP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#версия 2 (c Beam + температура)\n",
        "def generate_with_beam_search(matrix, id2word, bigr2id, n=100, max_beams=5, start='<start1> <start2>', temperature=1.3):\n",
        "    # изначально у нас один луч с заданным началом (start по дефолту)\n",
        "    initial_node = Beam(sequence=[start], score=np.log1p(0))\n",
        "    beams = [initial_node]\n",
        "\n",
        "    for i in range(n):\n",
        "        # делаем n шагов генерации\n",
        "        new_beams = []\n",
        "        # на каждом шаге продолжаем каждый из имеющихся лучей\n",
        "        for beam in beams:\n",
        "            # лучи которые уже закончены не продолжаем (но и не удаляем)\n",
        "            if beam.sequence[-1] == '<end>':\n",
        "                new_beams.append(beam)\n",
        "                continue\n",
        "\n",
        "\n",
        "            tokens = []\n",
        "            for el in beam.sequence:\n",
        "                tokens.extend(el.split())\n",
        "\n",
        "            last_bigram = tokens[-2] + ' ' + tokens[-1]\n",
        "\n",
        "            if last_bigram in bigr2id:\n",
        "                last_id = bigr2id[last_bigram]\n",
        "            else:\n",
        "                second_token = tokens[-1]\n",
        "                candidates = [bigr for bigr in bigr2id.keys() if bigr.split()[1] == second_token]\n",
        "                if candidates:\n",
        "                    last_id = bigr2id[random.choice(candidates)]\n",
        "                else:\n",
        "                    try:\n",
        "                        last_id = bigr2id[start]\n",
        "                    except:\n",
        "                        raise KeyError('Генерация с таким стартом невозможна')\n",
        "\n",
        "\n",
        "\n",
        "            # посмотрим вероятности продолжений для предыдущего слова\n",
        "            probas = matrix[last_id].toarray()[0]\n",
        "\n",
        "\n",
        "            if probas.sum() == 0:\n",
        "                top_idxs = [np.random.randint(0, matrix.shape[1])]\n",
        "            else:\n",
        "                #доп обработка! иначе ошибка на высоких температурах\n",
        "                probas_temp = apply_temperature(probas, temperature=temperature)\n",
        "                probas_temp /= probas_temp.sum()\n",
        "                top_idxs = np.random.choice(matrix.shape[1],\n",
        "                                        size=min(max_beams, probas.astype(bool).sum()),\n",
        "                                        p=probas_temp, replace=False)\n",
        "\n",
        "            for top_id in top_idxs:\n",
        "                # иногда вероятности будут нулевые, такое не добавляем\n",
        "                if not probas[top_id]:\n",
        "                    #поменяла на continue с надеждой, что предложения не будут обрываться слишком рано\n",
        "                    continue\n",
        "\n",
        "                # создадим новый луч на основе текущего и варианта продолжения\n",
        "                new_sequence = beam.sequence + [id2word[top_id]]\n",
        "\n",
        "\n",
        "\n",
        "                if len(new_sequence) > 35:   #они слишком длинные и всегда плохие\n",
        "                    continue\n",
        "\n",
        "                #попробуем как-то поощрять длинные предложения\n",
        "                length_bonus = 0.2 * np.log1p(len(new_sequence))\n",
        "\n",
        "\n",
        "                new_score = beam.score + np.log(max(probas[top_id], 1e-10)) + length_bonus\n",
        "                new_beam = Beam(sequence=new_sequence, score=new_score)\n",
        "                new_beams.append(new_beam)\n",
        "\n",
        "        # отсортируем лучи по скору и возьмем только топ max_beams\n",
        "        beams = sorted(new_beams, key=lambda x: x.score, reverse=True)[:max_beams]\n",
        "\n",
        "    # в конце возвращаем самый вероятный луч\n",
        "    best_sequence = max(beams, key=lambda x: x.score).sequence\n",
        "\n",
        "\n",
        "\n",
        "    return ' '.join(best_sequence)\n",
        "\n"
      ],
      "metadata": {
        "id": "zl08E8F5ctIo"
      },
      "id": "zl08E8F5ctIo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(3):\n",
        "    print(generate_with_beam_search(matrix_news, id2word_news, bigr2id_news, max_beams=10).replace(' <end>', '...').replace('<start1> <start2> ', ''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iymUcWmPfIMv",
        "outputId": "8fb3e479-de2c-4a14-e043-52f55ceeb345"
      },
      "id": "iymUcWmPfIMv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "по предварительным данным причиной пожара стало короткое замыкание в электропроводке загорелась торговая палатка огонь затем перекинулся на лесной опушке диаметром около километра восточнее сержень-юрта вчечне третьи сутки идет уничтожение этого бандформирования заявили военные...\n",
            "как сообщает риа новости...\n",
            "основной темой предстоящих бесед станет ход ближневосточного мирного процесса целиком ложится на нынешнее руководство mi 5 стелла римингтон закончила писать воспоминания о шерлоке холмсе запрещен для показа в кинотеатре ударник...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "по предварительным данным причиной пожара стало короткое замыкание в электропроводке загорелась торговая палатка огонь затем перекинулся на лесной опушке диаметром около километра восточнее сержень-юрта вчечне третьи сутки идет уничтожение этого бандформирования заявили военные...\n",
        "\n",
        "как сообщает риа новости...\n",
        "\n",
        "основной темой предстоящих бесед станет ход ближневосточного мирного процесса целиком ложится на нынешнее руководство mi 5 стелла римингтон закончила писать воспоминания о шерлоке холмсе запрещен для показа в кинотеатре ударник...\n"
      ],
      "metadata": {
        "id": "7IxJh2ePzVgF"
      },
      "id": "7IxJh2ePzVgF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c426746a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c426746a",
        "outputId": "d2a2b32d-9544-4d1f-8874-078043bf9287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "международный форум начинает работу третья министерская конференция всемирной торговой организации wto org выпуск и распространение вредоносных программ tribe flood network tfn и stacheldraht известны с прошлого лета на 14 центов до 28,92 долл за баррель...\n",
            "международный форум на высшем уровне между седьмым и восьмым кандидатами которые официально начали собирать нефть с поставкой сразу зафиксированы на алтуфьевском шоссе бибиревской улице волоколамское шоссе улице свободы улице генерала кузнецова в доверенности не было...\n",
            "международный форум где планируется проводить мониторинг всего траффика проходящего через данного провайдера...\n"
          ]
        }
      ],
      "source": [
        "for _ in range(3):\n",
        "    print(generate_with_beam_search(matrix_news, id2word_news, bigr2id_news, max_beams=10, start='международный форум').replace(' <end>', '...').replace('<start1> <start2> ', ''))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "международный форум начинает работу третья министерская конференция всемирной торговой организации wto org выпуск и распространение вредоносных программ tribe flood network tfn и stacheldraht известны с прошлого лета на 14 центов до 28,92 долл за баррель...\n",
        "\n",
        "международный форум на высшем уровне между седьмым и восьмым кандидатами которые официально начали собирать нефть с поставкой сразу зафиксированы на алтуфьевском шоссе бибиревской улице волоколамское шоссе улице свободы улице генерала кузнецова в доверенности не было...\n",
        "\n",
        "международный форум где планируется проводить мониторинг всего траффика проходящего через данного провайдера...\n"
      ],
      "metadata": {
        "id": "dlypoJ7pzceJ"
      },
      "id": "dlypoJ7pzceJ"
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(3):\n",
        "    print(generate_with_beam_search(matrix_news, id2word_news, bigr2id_news, max_beams=10, start='быстрый рост').replace(' <end>', '...').replace('<start1> <start2> ', ''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBHi1pP2L758",
        "outputId": "74877b02-a2ec-46f8-f587-c9baf77688d8"
      },
      "id": "DBHi1pP2L758",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "быстрый рост курса иены обусловили снижение цен фьючерсов на сырую нефть достигла рекордной для второго квартала уже будет составлен свой маркетинговый профайл после матчей сша словакия чехия латвия швейцария канада швеция финляндия...\n",
            "быстрый рост и размножение раковых клеток прекращается и они сейчас унитожаются огнем артиллерии уничтожены такжедва автомобиля уаз убиты восемь сербов включая четырехлетнего ребенка и ранив двух милиционеров пустыми бутылками и банками из-под пива...\n",
            "быстрый рост региональных банков...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "быстрый рост курса иены обусловили снижение цен фьючерсов на сырую нефть достигла рекордной для второго квартала уже будет составлен свой маркетинговый профайл после матчей сша словакия чехия латвия швейцария канада швеция финляндия...\n",
        "\n",
        "быстрый рост и размножение раковых клеток прекращается и они сейчас унитожаются огнем артиллерии уничтожены такжедва автомобиля уаз убиты восемь сербов включая четырехлетнего ребенка и ранив двух милиционеров пустыми бутылками и банками из-под пива...\n",
        "\n",
        "быстрый рост региональных банков...\n"
      ],
      "metadata": {
        "id": "pf7KeAuOzhhp"
      },
      "id": "pf7KeAuOzhhp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "ВЫВОД\n",
        "\n",
        "generate_with_beam_search работает лучше.\n",
        "\n",
        "Оказалось, его можно даже немного настроить, чтобы предложения были не слишком короткие (это была основная проблема)"
      ],
      "metadata": {
        "id": "fNjzljVbcGbm"
      },
      "id": "fNjzljVbcGbm"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oHwFxa6TxNZ_"
      },
      "id": "oHwFxa6TxNZ_",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}